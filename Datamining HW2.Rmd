---
title: "HW 2"
author: "Ashesh Shrestha"
date: "3/9/2021"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ECO 395: Exercises 2

## Problem 1: Visualization

```{r, message=FALSE, echo=FALSE}
library(ggplot2)
library(tidyverse)
capmetro_UT <- read.csv("~/Downloads/ECO395M-master/data/capmetro_UT.csv")
```

```{r, message=FALSE, echo=FALSE}
# Recode the categorical variables in sensible, rather than alphabetical, order
capmetro_UT = mutate(capmetro_UT,
              day_of_week = factor(day_of_week,
                  levels=c("Mon", "Tue", "Wed","Thu", "Fri", "Sat", "Sun")),
              month = factor(month,
                  levels=c("Sep", "Oct","Nov")))
C1= capmetro_UT %>%
  group_by(month, day_of_week,hour_of_day) %>%
  summarize(average_boardings = mean(boarding))
```

```{r, message=FALSE, echo=FALSE, fig.width=12, fig.height =8}
ggplot(data= C1)+
  geom_line(mapping=aes(x= factor(hour_of_day), y= average_boardings, group = month, color= month))+
  facet_wrap(~day_of_week, nrow= 3) +
  labs(
    title = "Figure 1.1 Average Boardings",
    x = "Hour of the day",
    y= "Average Boardings"
  )
```

As seen in the Figure 1.1, hour of peak boarding remains broadly similar across days. The highest average boarding is observed during 3 pm hour to 5 pm hour of each day. Another thing that we can observe in the figure is that average boarding on Mondays of September remains lower across hours of the day compared to other days and month. Similarly, we can also see that average boarding on Wednesdays, Thursdays and Fridays in November are lower. While it is difficult to accurately predict the reason behind so, one of possible reasons can be that the number of classes scheduled on Mondays during the month of September might be lower, whereas the number of classes scheduled on Wednesdays, Thursdays and Fridays could be lower on November.

```{r, message=FALSE, echo=FALSE, fig.width =12, fig.height=15}
ggplot(data= capmetro_UT)+
  geom_point(aes(x= temperature, y=boarding, color= weekend))+
  facet_wrap(~hour_of_day, nrow= 5)+
  labs(
    title = "Figure 1.2 Boardings v temperature in each 15-minute window faceted by hour of the day",
    x = "Temperature",
    y= "Boardings"
  )
```

Figure 1.2 presents the scatterplot of boardings by temperature on weekdays and weekends faceted by hours of the day. As evident in the figure, when we hold hours of the day and weekend status constant, we do not see any noticeable effect of temperature on the number of UT students riding the bus.

## Problem 2: Saratoga house prices

```{r, message=FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(caret)
library(foreach)
data(SaratogaHouses)
```

```{r, message=FALSE, echo=FALSE, warning= FALSE}
#For linear model
#Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)

#K- fold cross validation
saratoga_folds = crossv_kfold(SaratogaHouses, k=10)

#map the model-fitting function and use K-fold cross validation
Model_medium = map(saratoga_folds$train, ~ lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=.))
Model_main = map(saratoga_folds$train, ~ lm(price ~ lotSize + age + landValue + livingArea + bedrooms + fireplaces + bathrooms + rooms + heating + fuel + centralAir + age*centralAir + lotSize*landValue + bedrooms*rooms + fireplaces*heating, data=.))
```

Mean RMSE for medium model 
```{r, message=FALSE, echo=FALSE} 
map2_dbl(Model_medium, saratoga_folds$test, modelr::rmse) %>% mean
```

Mean RMSE for main linear model 
```{r, message=FALSE, echo=FALSE} 
map2_dbl(Model_main, saratoga_folds$test, modelr::rmse) %>% mean
```

```{r, message=FALSE, echo=FALSE, warning = FALSE} 
#k-nearest neighbors model
#rescaling all except categorical variables
saratoga_scale= SaratogaHouses %>%
  mutate(across(c(lotSize, age, landValue, livingArea, pctCollege, bedrooms, fireplaces, bathrooms, rooms), scale))

#Split rescaled data into training and testing sets
saratoga_scale_split = initial_split(saratoga_scale, prop = 0.8)
saratoga_scale_train = training(saratoga_scale_split)
saratoga_scale_test = testing(saratoga_scale_split)

saratoga_scale_folds = crossv_kfold(saratoga_scale, k=10)
```

Mean RMSE for k nearest neighbors with various k values
```{r, message=FALSE, echo=FALSE, warning = FALSE} 
#K- fold cross validation across a range of k
k_grid = c(2, 5, 10, 20, 50, 75, 100, 200, 300, 400)

cv_grid = foreach(k= k_grid, .combine= 'rbind') %dopar% {
  modelk = map(saratoga_scale_folds$train, ~knnreg(price~ lotSize + age + landValue + livingArea + bedrooms + fireplaces + bathrooms + rooms + heating + fuel + centralAir, k = k, data =. , use.all=FALSE))
  RMSE = map2_dbl(modelk, saratoga_scale_folds$test, modelr::rmse)
  c(k=k, RMSE = mean(RMSE))
} %>% as.data.frame

cv_grid
```

I have built a linear and k-nearest neighbors regression models for prediction of house prices. I have chosen several features which affects the price of a house. For the linear model, I have included lot size, age, land value, living area, number of bedrooms, number of bathrooms, number of fireplaces, number of rooms, type of heating system, type of fuel used, availability of central air, interaction between age and central air, interaction between lot size and land value, interaction between number of bedrooms and rooms, and interaction between number fireplaces and type of heating system for predicting house price. 

Similarly for the k-nearest neighbors, I have chosen lot size, age, land value, living area, number of bedrooms, fireplaces, number of bathrooms, number of rooms. type of heating system, type of fuel, and availability of central air as feature variables. As the k- nearest neighbors model is adaptable to find interactions and nonlinearities, I have not included interaction between the feature variables in the model.

After running both the models and measuring the out-of-sample performance by averaging the estimates of out-of-sample root mean squared error (RMSE) over many different train/test splits, I have found that average RMSE of k- nearest neighbors with k=20  is lower and hence perform relatively better.

## Problem 3: Classification and retrospective sampling

```{r, message=FALSE, echo=FALSE} 
library(ggplot2)
library(tidyverse)
library(modelr)
library(rsample)
library(caret)
library(foreach)
german_credit <- read.csv("~/Documents/GitHub/ECO395M/data/german_credit.csv")
```

```{r, message=FALSE, echo=FALSE, results =FALSE} 
german_credit %>%
  group_by(history, Default) %>%
  summarize(count=n())
        
german_credit %>%
  group_by(history) %>%
  summarize(count=n())
```

```{r, message=FALSE, echo=FALSE}
Default_probability = c(0.6, 0.31, 0.17)
barplot(Default_probability,
        main= 'Figure 3.1 Default probability by credit history',
        xlab= 'History', ylab = 'Probability',
        names.arg=c('Good', 'Poor', 'Terrible'))
```

```{r, message=FALSE, echo=FALSE}
#For Logit model
#Split into training and testing sets
logit_default= glm(Default~ duration + amount + installment + age + history + purpose + foreign, data = german_credit, family = 'binomial') 
coef(logit_default) %>% round(2)
```

Figure 3.1  shows bar plot of default probabilities for people with different credit histories, namely good, bad and terrible. The probabilities are quite counterintuitive. The probability of default for borrowers with good credit history is 0.6 while that for bad credit history is just above 0.3 and one for terrible history is 0.17. 

Likewise, the coefficient of  poor history and terrible history derived from the logit model are -1.11 and -1.88 respectively. This implies that having poor credit history multiplies the odds of default by approximately 0.33 while having terrible credit history multiplies the odds of default by approximately 0.15. Looking at the probabilities and coefficients of the logit model derived from given data, we see that the odds of default increases as credit history improves . 

As defaults were rare, the bank sampled a set of loans that had defaulted for inclusion in the study. It then attempted to match each default with similar sets of loans that had not defaulted, including all reasonably close matches in the analysis. This resulted in a substantial oversampling of defaults, relative to a random sample of loans in the bank's overall portfolio. Therefore, this data set is not appropriate for building a predictive model of defaults if the purpose of the model is to screen prospective borrowers to classify them into "high" versus "low" probability of default. For doing so, the bank should resort to random sampling which would prevent oversampling of defaults.

## Problem 4: Children and hotel reservations

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(caret)
library(foreach)
hotels_dev <- read.csv("~/Documents/GitHub/ECO395M/data/hotels_dev.csv")
hotels_val <- read.csv("~/Documents/GitHub/ECO395M/data/hotels_val.csv")
```

```{r, message=FALSE, echo=FALSE}
#Split into training and testing sets
hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_train = training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)
```

```{r, message=FALSE, echo=FALSE, warning= FALSE}
#Fit the linear models
lm_hotels_dev1= lm(children ~ market_segment + adults + customer_type + is_repeated_guest, data= hotels_dev_train)

lm_hotels_dev2= lm(children ~ hotel + lead_time + stays_in_weekend_nights + stays_in_week_nights +adults + meal + market_segment + distribution_channel + is_repeated_guest +previous_cancellations + previous_bookings_not_canceled + reserved_room_type +assigned_room_type + booking_changes + deposit_type + days_in_waiting_list + customer_type + average_daily_rate + required_car_parking_spaces + total_of_special_requests, data= hotels_dev_train)

lm_hotels_dev3= lm(children ~  hotel + lead_time + stays_in_weekend_nights + stays_in_week_nights +adults + meal + market_segment + distribution_channel + is_repeated_guest +previous_cancellations + previous_bookings_not_canceled + reserved_room_type +assigned_room_type + booking_changes + deposit_type + days_in_waiting_list + customer_type + average_daily_rate + required_car_parking_spaces + total_of_special_requests +stays_in_weekend_nights * reserved_room_type + is_repeated_guest* average_daily_rate + lead_time * total_of_special_requests +I(adults^2) + reserved_room_type*meal, data= hotels_dev_train)
```

```{r, message=FALSE, echo=FALSE, warning = FALSE, results= FALSE}
#Predictions out of sample
#Root mean squared error
rmse(lm_hotels_dev1, hotels_dev_test)
rmse(lm_hotels_dev2, hotels_dev_test)
rmse(lm_hotels_dev3, hotels_dev_test )
```

```{r, message=FALSE, echo=FALSE, warning= FALSE}
#K- fold cross validation
hotels_dev_folds = crossv_kfold(hotels_dev, k=10)

#map the model-fitting function and use K-fold cross validation
lm_hotels_dev1_K = map(hotels_dev_folds$train, ~ lm(children ~ market_segment + adults + customer_type + is_repeated_guest, data= . ))

lm_hotels_dev2_K = map(hotels_dev_folds$train, ~ lm(children ~ hotel + lead_time + stays_in_weekend_nights + stays_in_week_nights + adults + meal + market_segment + distribution_channel + is_repeated_guest + previous_cancellations + previous_bookings_not_canceled + reserved_room_type +assigned_room_type + booking_changes + deposit_type + days_in_waiting_list + customer_type + average_daily_rate + required_car_parking_spaces + total_of_special_requests, data= . ))

lm_hotels_dev3_K = map(hotels_dev_folds$train, ~ lm(children ~  hotel + lead_time + stays_in_weekend_nights + stays_in_week_nights + adults + meal + market_segment + distribution_channel + is_repeated_guest + previous_cancellations + previous_bookings_not_canceled + reserved_room_type + assigned_room_type + booking_changes + deposit_type + days_in_waiting_list +customer_type + average_daily_rate + required_car_parking_spaces + total_of_special_requests + stays_in_weekend_nights * reserved_room_type + is_repeated_guest * average_daily_rate + lead_time * total_of_special_requests + I(adults^2) + reserved_room_type*meal, data= .))
```

Baseline 1: Mean RMSE
```{r, message=FALSE, echo=FALSE, warning = FALSE}
#map the RMSE calculation over the trained models and test sets simultaneously
map2_dbl(lm_hotels_dev1_K, hotels_dev_folds$test, modelr::rmse) %>% mean
```

Baseline 2: Mean RMSE
```{r, message=FALSE, echo=FALSE, warning = FALSE}
map2_dbl(lm_hotels_dev2_K, hotels_dev_folds$test, modelr::rmse) %>% mean
```

Main linear model: Mean RMSE
```{r, message=FALSE, echo=FALSE, warning = FALSE}
map2_dbl(lm_hotels_dev3_K, hotels_dev_folds$test, modelr::rmse) %>% mean   
```

```{r, message=FALSE, echo=FALSE, warning=FALSE, fig.width=12, fig.height =10}
#ROC curve
phat_hotels_val = predict(lm_hotels_dev3, hotels_val )

thresh_grid = seq(0.95, 0.05, by=-0.005)
roc_curve_hotels_dev = foreach(thresh = thresh_grid, .combine='rbind') %do% {
  yhat_hotels_val = ifelse(phat_hotels_val >= thresh, 1, 0)
  
# FPR, TPR for linear model
confusion_out_lm_hotels_dev3 = table(y = hotels_val$children, yhat = yhat_hotels_val)
  
  out_lm_hotels_dev3 = data.frame(
    TPR = confusion_out_lm_hotels_dev3[2,2]/sum(hotels_val$children==1),
    FPR = confusion_out_lm_hotels_dev3[1,2]/sum(hotels_val$children==0))
  rbind(out_lm_hotels_dev3)
} %>% as.data.frame()

ggplot(roc_curve_hotels_dev) + 
  geom_line(aes(x=FPR, y=TPR)) + 
  labs(title="Figure 4.1: ROC curve") +
  theme_bw(base_size = 10) 
```

```{r, message=FALSE, echo=FALSE, warning= FALSE, results= FALSE}
K_folds = 20

hotels_val = hotels_val %>%
  mutate(fold_id= rep(1:K_folds, length= nrow(hotels_val)) %>% sample())


hotels_val_fold_id1= hotels_val %>%
  filter(fold_id == 1) 
phat_hotels_val_fold_id1 = predict(lm_hotels_dev3, hotels_val_fold_id1 )
sum(phat_hotels_val_fold_id1)
sum(hotels_val_fold_id1$children)

hotels_val_fold_id2= hotels_val %>%
  filter(fold_id == 2)
phat_hotels_val_fold_id2 = predict(lm_hotels_dev3, hotels_val_fold_id2 )
sum(phat_hotels_val_fold_id2)
sum(hotels_val_fold_id2$children)

hotels_val_fold_id3= hotels_val %>%
  filter(fold_id == 3)
phat_hotels_val_fold_id3 = predict(lm_hotels_dev3, hotels_val_fold_id3 )
sum(phat_hotels_val_fold_id3)
sum(hotels_val_fold_id3$children)

hotels_val_fold_id4= hotels_val %>%
  filter(fold_id == 4)
phat_hotels_val_fold_id4 = predict(lm_hotels_dev3, hotels_val_fold_id4 )
sum(phat_hotels_val_fold_id4)
sum(hotels_val_fold_id4$children)

hotels_val_fold_id5= hotels_val %>%
  filter(fold_id == 5)
phat_hotels_val_fold_id5 = predict(lm_hotels_dev3, hotels_val_fold_id5 )
sum(phat_hotels_val_fold_id5)
sum(hotels_val_fold_id5$children)

hotels_val_fold_id6= hotels_val %>%
  filter(fold_id == 6)
phat_hotels_val_fold_id6 = predict(lm_hotels_dev3, hotels_val_fold_id6)
sum(phat_hotels_val_fold_id6)
sum(hotels_val_fold_id6$children)

hotels_val_fold_id7= hotels_val %>%
  filter(fold_id == 7)
phat_hotels_val_fold_id7 = predict(lm_hotels_dev3, hotels_val_fold_id7 )
sum(phat_hotels_val_fold_id7)
sum(hotels_val_fold_id7$children)

hotels_val_fold_id8= hotels_val %>%
  filter(fold_id == 8)
phat_hotels_val_fold_id8 = predict(lm_hotels_dev3, hotels_val_fold_id8 )
sum(phat_hotels_val_fold_id8)
sum(hotels_val_fold_id8$children)

hotels_val_fold_id9= hotels_val %>%
  filter(fold_id == 9)
phat_hotels_val_fold_id9 = predict(lm_hotels_dev3, hotels_val_fold_id9 )
sum(phat_hotels_val_fold_id9)
sum(hotels_val_fold_id9$children)

hotels_val_fold_id10= hotels_val %>%
  filter(fold_id == 10)
phat_hotels_val_fold_id10 = predict(lm_hotels_dev3, hotels_val_fold_id10 )
sum(phat_hotels_val_fold_id10)
sum(hotels_val_fold_id10$children)

hotels_val_fold_id11= hotels_val %>%
  filter(fold_id == 11)
phat_hotels_val_fold_id11 = predict(lm_hotels_dev3, hotels_val_fold_id11 )
sum(phat_hotels_val_fold_id11)
sum(hotels_val_fold_id11$children)

hotels_val_fold_id12= hotels_val %>%
  filter(fold_id == 12)
phat_hotels_val_fold_id12 = predict(lm_hotels_dev3, hotels_val_fold_id12 )
sum(phat_hotels_val_fold_id12)
sum(hotels_val_fold_id12$children)

hotels_val_fold_id13= hotels_val %>%
  filter(fold_id == 13)
phat_hotels_val_fold_id13 = predict(lm_hotels_dev3, hotels_val_fold_id13 )
sum(phat_hotels_val_fold_id13)
sum(hotels_val_fold_id13$children)

hotels_val_fold_id14= hotels_val %>%
  filter(fold_id == 14)
phat_hotels_val_fold_id14 = predict(lm_hotels_dev3, hotels_val_fold_id14)
sum(phat_hotels_val_fold_id14)
sum(hotels_val_fold_id14$children)

hotels_val_fold_id15= hotels_val %>%
  filter(fold_id == 15)
phat_hotels_val_fold_id15 = predict(lm_hotels_dev3, hotels_val_fold_id15 )
sum(phat_hotels_val_fold_id15)
sum(hotels_val_fold_id15$children)

hotels_val_fold_id16= hotels_val %>%
  filter(fold_id == 16)
phat_hotels_val_fold_id16 = predict(lm_hotels_dev3, hotels_val_fold_id16 )
sum(phat_hotels_val_fold_id16)
sum(hotels_val_fold_id16$children)

hotels_val_fold_id17= hotels_val %>%
  filter(fold_id == 17)
phat_hotels_val_fold_id17 = predict(lm_hotels_dev3, hotels_val_fold_id17 )
sum(phat_hotels_val_fold_id17)
sum(hotels_val_fold_id17$children)

hotels_val_fold_id18= hotels_val %>%
  filter(fold_id == 18)
phat_hotels_val_fold_id18 = predict(lm_hotels_dev3, hotels_val_fold_id18 )
sum(phat_hotels_val_fold_id18)
sum(hotels_val_fold_id18$children)

hotels_val_fold_id19= hotels_val %>%
  filter(fold_id == 19)
phat_hotels_val_fold_id19 = predict(lm_hotels_dev3, hotels_val_fold_id19 )
sum(phat_hotels_val_fold_id19)
sum(hotels_val_fold_id19$children)

hotels_val_fold_id20= hotels_val %>%
  filter(fold_id == 20)
phat_hotels_val_fold_id20 = predict(lm_hotels_dev3, hotels_val_fold_id20 )
sum(phat_hotels_val_fold_id20)
sum(hotels_val_fold_id20$children)
```

```{r, message=FALSE, echo=FALSE}
library(knitr)
Fold_id = c(1, 2, 3, 4, 5, 6 ,7 , 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
Actual = c(sum(hotels_val_fold_id1$children), sum(hotels_val_fold_id2$children), sum(hotels_val_fold_id3$children), sum(hotels_val_fold_id4$children), sum(hotels_val_fold_id5$children), sum(hotels_val_fold_id6$children), sum(hotels_val_fold_id7$children), sum(hotels_val_fold_id8$children), sum(hotels_val_fold_id9$children), sum(hotels_val_fold_id10$children), sum(hotels_val_fold_id11$children), sum(hotels_val_fold_id12$children), sum(hotels_val_fold_id13$children), sum(hotels_val_fold_id14$children), sum(hotels_val_fold_id15$children), sum(hotels_val_fold_id16$children), sum(hotels_val_fold_id17$children), sum(hotels_val_fold_id18$children), sum(hotels_val_fold_id19$children), sum(hotels_val_fold_id20$children))

Expected = c(sum(phat_hotels_val_fold_id1), sum(phat_hotels_val_fold_id2), sum(phat_hotels_val_fold_id3), sum(phat_hotels_val_fold_id4), sum(phat_hotels_val_fold_id5), sum(phat_hotels_val_fold_id6), sum(phat_hotels_val_fold_id7), sum(phat_hotels_val_fold_id8), sum(phat_hotels_val_fold_id9), sum(phat_hotels_val_fold_id10), sum(phat_hotels_val_fold_id11), sum(phat_hotels_val_fold_id12), sum(phat_hotels_val_fold_id13), sum(phat_hotels_val_fold_id14), sum(phat_hotels_val_fold_id15), sum(phat_hotels_val_fold_id16), sum(phat_hotels_val_fold_id17), sum(phat_hotels_val_fold_id18), sum(phat_hotels_val_fold_id19),sum(phat_hotels_val_fold_id20))
```

```{r, message=FALSE, echo=FALSE}
Comparison_table= data.frame(Fold_id, Actual, Expected)
kable(Comparison_table, caption = 'Actual v expected number of bookings with childen')
```


As seen in Table 1, out of 20 folds each with 250 observations, for 50 percent of the folds, the model has overpredicted the number of bookings with children. On the other hand, for 40 percent of the folds, the model has underpredicted the number of bookings with children. The model has exactly predicted the number of bookings with children for 10 percent of the folds. The maximum difference between actual and expected  number of bookings with children in any fold is 8. Given the results, I think my model performed pretty well in predicting the total number of bookings with children.
  

  